---
title: "script for  'Increased population density depresses activity but does not influence emigration in the snail *Pomatias elegans*'"
author: 
  - "**Maxime Dahirel** (script author)"
  - Loïc Menut
  - Armelle Ansart
date:
output: 
  html_document:
    theme: yeti
    toc: TRUE
    toc_float: TRUE
    code_download: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

## **Introduction**

The aims of this study were to:

- determine whether dispersal and activity are density-dependent in *Pomatias elegans*
- determine whether these two traits were linked
- determine whether there was a link between behaviour and morphological defence, using (relative) shell weight as a proxy for the latter

To do so, we exposed snails to different densities and examined their dispersal and activity responses (binary traits); we then weighted their shells. We analysed these data using a multivariate mixed model approach.

(see manuscript for details)


## **Starters and data wrangling**

First, let's load the packages we'll need:

```{r load-packages}
library(here)
library(arm)
library(matrixStats)
library(tidyverse)
library(rstan)
## ^may be worth changing this to cmdstanr if you are reading this post summer 2020
## look into the documentation of both rstan and cmdstanr, and use the backend argument in brm() to specify which one you want to use
## as of august 2020 rstan versions>2.19.3 cause known problems. Do not update without checking these are solved (you can roll back if you did)
library(tidybayes)
library(bayesplot)
library(brms)
library(patchwork)
rstan_options(auto_write = TRUE)
options(mc.cores = 2)
```

Now we load the raw data files:
```{r load-raw-datafiles}
## Load raw dataset
data0 <- read.table(here("data/dataset_main_pomatias.txt"), header = TRUE)
shell_info <- read.table(here("data/dataset_shellmass_pomatias.txt"), header = TRUE)
# data_discrimin <- read.table(here("/discrimin_pomatias.txt"), header = TRUE)
## the data_discrimin dataset contains info of the snails used for the initial LDA for sex (see manuscript), but is not used in the final analysis
```

The `data0` dataset contains the following columns:

- `ID` : unique individual ID
- `Date` : (format dd/mm/yy) day the dispersal test was started
- `Box_code`: numeric code of test box during dispersal. Box_codes are only unique within test dates; you need to combine it with `Date` to get a unique code for each box (this wil be done below)
- `Density`: number of individuals in the same box during the dispersal test
- `Sex_true`: (M = male, F = female) sex determined by dissection after the tests, using presence of male genitalia = male as a criterion
- `Sex_predicted`: sex inferred from a Linear Discriminant Analysis using shell morphometrics; used for assigning snails to boxes in an approximately sex-balanced fashion
- `Disp` : (binary no/yes) whether or not the snail dispersed (crossed to the second half of the two-patch system) after 4 days of test
- `Time_sec` : (in seconds) time to activity during the activity test. Values >= 1200 are censored, that is, they denote the time at which we stopped observing, NOT the time at which they become active 
- `Active` : (binary 0/1) whether or not the snail got active during the test (before 20 min)
- `Height`, `Diametre`, `PeristomeH` : Shell height, width and aperture height for each shell (in mm) 

The `shell_info` dataset adds shell information not present in the main dataset and contains 4 columns: 

- `uniqueID` : a number uniquely identifying each individual (note that this number is contained in the `ID` string of `data0` after the first "_"; this will be used to merge them)
- `Shell_Mass1` and `Shell_Mass2`:  successive measures of shell mass for each snail (in mg)
- `area` : (unused, in cm^2^) shell area when photographed as in Fig. 1 of the article

For our analysis, we're going to need to (a) combine the `data0` and `shell_info` datasets, (b) create a bunch of new variables from the original ones, and (c) convert the dataset into a "long" format where both shell mass measures are in the same column, as well as both behavioural measures (the latter is not strictly needed, but it makes fitting a "latent" behavioural variable way easier).

So let's do that:

```{r data-wrangling1}
## creation of new variables
data <- as_tibble(data0) %>%
  mutate(
    BOX = factor(interaction(Date, Box_code)),
    Disp2 = -0.5 + as.numeric(Disp == "yes"), ## centered dummy variable ##for supplementary material only
    Active2 = -0.5 + as.numeric(Active == 1), ## centered dummy variable ##for supplementary material only
    is.female = -0.5 + as.numeric(Sex_true == "F"), ## centered dummy variable
    scale_Density = scale(Density),
    uniqueID = as.numeric(str_split_fixed(ID, "_", 3)[, 2])
  ) %>%
  left_join(shell_info) %>%
  mutate(behave_Disp = as.numeric(Disp == "yes"), behave_Active = Active) %>%
  select(Date, BOX, uniqueID, ID,
    Density, scale_Density,
    Sex_predicted,
    Sex_dissection = Sex_true, is.female, ### rename Sex variable to something more "accurate"
    Shell_height = Height, Shell_width = Diametre, Aperture_height = PeristomeH, ### renamed morpho variables to something more accurate
    Shell_Mass1, Shell_Mass2,
    Disp2, Active2, behave_Active, behave_Disp, Time_sec
  )
```

```{r data-wrangling2}

data1 <- data %>%
  select(-c(behave_Active, behave_Disp)) %>%
  pivot_longer(
    names_prefix = "Shell_Mass",
    names_to = "measurement_order",
    values_to = "Shell_mass",
    cols = contains("Shell_Mass")
  ) %>%
  mutate(measurement_order = as.numeric(measurement_order))

data2 <- data %>%
  select(-c(Shell_Mass1, Shell_Mass2)) %>%
  pivot_longer(
    names_to = "which_behaviour",
    values_to = "behave",
    cols = contains("behave")
  ) %>%
  mutate(measurement_order = as.numeric(which_behaviour == "behave_Active") + 1)


data <- left_join(data1, data2) %>%
  mutate(which_behaviour = fct_recode(which_behaviour, Active = "behave_Active", Disp = "behave_Disp"))
```

```{r data-wrangling3}
data <- data %>%
  mutate(
    scale_logshellmass = scale(log(Shell_mass)),
    scale_logheight = scale(log(Shell_height))
  ) # %>%
# mutate(scale_logshellmass_NAfilled=replace_na(scale_logshellmass,0), ###needed for the subset() approach
#     is.shell.valid=as.numeric(is.na(Shell_Mass)==FALSE))  ### the is.shell.valid variable ensures the filled NAs are ignored during fitting for the subset() approach
```

... and *Voilà*! We have our final dataset! But what's in it, you may ask? Let's look:

- `Date`, `uniqueID`, `ID`, `Density`, `Sex_predicted` and `Time_sec` are the same as above 
-  `Sex_dissection`, `Shell_width`, `Shell_height` and `Aperture_height` are renamed versions of `Sex_true`,  `Diametre`, `Height`, `PeristomeH` for accuracy (they are otherwise unchanged) 
- `scale_Density` : `Density`, centred and scaled to unit 1SD
- `BOX` : a unique identifier for each group/box of snails we tested
- `is.female` : a dummy numerical variable (-0.5 for `Sex_dissection` = Male, +0.5 for Female)
- `Disp2` / `Active2`: dummy numerical variables (-0.5 for resident/inactive, +0.5 for disperser / active)
- `Shell_mass` : `Shell_Mass1` and `Shell_Mass2`, converted to long format
- `behave` : (binary 0/1) did the individual showed the behaviour denoted in `which_behaviour` during the corresponding test?
- `measurement order`: 1 or 2, is it the first measure of `Shell_Mass` / `behave` or the second? (for `behave`, Dispersal always comes first, then Activity)
- `scale_logshellmass` : `Shell_mass`, ln-transformed and then centred+scaled to unit 1SD
- `scale_logheight` : `Shell_height`, ln-transformed and then centred+scaled to unit 1SD

## **Main model**

Now, let's fit our main model (please see description in the methods and supplementary material of the paper).
Note how it is a trivariate model (Dispersal, Activity, Shell Mass) but only two submodels are fitted. That's on purpose, we grouped Dispersal and Activity in the same variable and submodel to make it easier to write in the shared random effect of individual `ID` (which corresponds to a latent behavioural variable).

It should need 10000-20000 iterations per chain post-warmup to reach satisfactory effective sample sizes for everything (depends on your threshold). It's the individual SDs and correlation that cause the most problem, other parameters are fine with 10-25% of that number. Runtime on a laptop with 2 cores used in parallel and 12 Gb memory: about 5-6h. If you just want to have a quick look, convergence happens much, **much** faster, within a few 100s of iterations. Just set `iter` to 250-500 for instance and `warmup` to half of that; chains should look good enough to have a general idea of what's happening

```{r main-model}

if (file.exists(here("R_output", "model_main.Rdata")))
# this if-else statement is avoid re-fitting a model when knitting Rmd file if there is already one existing in R_output
# to override, re-run the model and re-save manually by selecting relevant code lines then knit (or delete the Rdata object)
  {
    load(here("R_output", "model_main.Rdata"))
  } else {
  #### first, our priors
  prior <- c(
    set_prior("normal(0,1)", class = "Intercept", resp = c("scalelogshellmass")),
    set_prior("normal(0,1)", class = "b", resp = c("behave", "scalelogshellmass")),
    set_prior("normal(0,1.5)", class = "b", resp = "behave", coef = c("which_behaviourActive", "which_behaviourDisp")),
    set_prior("normal(0,1)", class = "sd", resp = c("behave", "scalelogshellmass")),
    set_prior("normal(0,1)", class = "sigma", resp = "scalelogshellmass"),
    set_prior("lkj(2)", class = "cor")
  )

  #### then, our submodels

  bf_behave <- bf(behave ~ 0 + which_behaviour + which_behaviour:(scale_Density + scale_logheight + is.female) + (0 + which_behaviour | Date) +
    (0 + which_behaviour | BOX) + (1 | q | ID), family = bernoulli)

  bf_shell_miss <- bf(scale_logshellmass | mi() ~ scale_logheight + is.female + (1 | q | ID))

  ## an alternative to missing data imputation with mi() would be to use the subset() approach, essentially ignoring the NA values, but only for the response with NA
  ## that is, no deletion of entire rows
  ### leads to sensibly the same results in our case (as expected when missing data are only in responses)
  # bf_shell_subset<-bf(scale_logshellmass_NAfilled|subset(is.shell.valid) ~ scale_logheight + is.female+(1|q|ID))

  mod <- brm(mvbf(bf_behave + bf_shell_miss),
    data = data, prior = prior, iter = 25000, warmup = 5000, # 25000 5000
    control = list(adapt_delta = 0.95, max_treedepth = 15), chains = 4, seed = 42
  )

  save(list = "mod", file = here("R_output", "model_main.Rdata"))
}
```

Now, some post-fitting checks:

```{r some-posterior-checking}
summary(mod) ## everything looks good

## but summary.brmsfit gives mean and 95% quantile interval
## I would like mean and HDI instead

summary_mod <- mod %>%
  posterior_samples() %>%
  select(starts_with(c("Intercept", "b_", "sd_", "cor_", "sigma"))) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi()

summary_mod

mcmc_rank_overlay(mod, pars = summary_mod$name)
# a bit wonky at the extreme ranks for the cor_ID and sd_ID_behave, but still okay-ish hopefully
# pretty good everywhere else

pp_check(mod, resp = "behave") ## not really informative given it's a binary variable
pp_check(mod, resp = "scalelogshellmass", newdata = data %>% filter(is.na(scale_logshellmass) == FALSE))
### need to make the pp_check on a dataset without the NAs or fail
### this one is not really informative either; we have a random effect of ID so it's a given it should look good
### unless we'd spectacularly failed with the residual variation
### but still good to check
### see ?pp_check for other possibilities
```

And let's extract the random variances/ covariances for Table 1 and 2
```{r Table1-part}
VarCorr(mod, summary = FALSE)$ID$cov[, "scalelogshellmass_Intercept", "scalelogshellmass_Intercept"] %>% mean_hdi()
VarCorr(mod, summary = FALSE)$ID$cov[, "behave_Intercept", "scalelogshellmass_Intercept"] %>% mean_hdi()
VarCorr(mod, summary = FALSE)$ID$cov[, "behave_Intercept", "behave_Intercept"] %>% mean_hdi()

VarCorr(mod, summary = FALSE)$Date$cov[, "behave_which_behaviourActive", "behave_which_behaviourActive"] %>% mean_hdi()
VarCorr(mod, summary = FALSE)$Date$cov[, "behave_which_behaviourDisp", "behave_which_behaviourDisp"] %>% mean_hdi()

VarCorr(mod, summary = FALSE)$BOX$cov[, "behave_which_behaviourActive", "behave_which_behaviourActive"] %>% mean_hdi()
VarCorr(mod, summary = FALSE)$BOX$cov[, "behave_which_behaviourDisp", "behave_which_behaviourDisp"] %>% mean_hdi()

VarCorr(mod, summary = FALSE)$residual__$sd^2 %>% mean_hdi()
```


## **Making figures**

(Fig. 1 is a shell photograph and a experimental design diagram, so we start at Fig.2 for data plots)

### Figure 2

For the first figure, we want to look at how dispersal and activity probability are predicted to change with density, and plot observed data along the way:

```{r fig2}
# first we create a newdata to which we add the posterior predictions (averaging out random effects, effects of sex and size)
newdata <- data %>%
  select(which_behaviour) %>%
  distinct() %>%
  expand_grid(BOX = data$BOX[1], ID = data$ID[1], is.female = 0, scale_logheight = 0, Density = c(1:30)) %>%
  mutate(scale_Density = (Density - attr(data$scale_Density, "scaled:center")) / attr(data$scale_Density, "scaled:scale")) %>%
  add_fitted_draws(mod, resp = "behave", re_formula = NA)

# then the two subplots:
p2a <- newdata %>%
  filter(which_behaviour == "Disp") %>%
  ggplot() +
  stat_lineribbon(aes(x = Density, y = .value), ## predictions
    .width = c(0.66, 0.84, 0.95), point_interval = mean_hdi,
    alpha = 0.9
  ) +
  geom_point(
    data = data %>% filter(which_behaviour == "Disp") %>% ## average of observed data at the box level
      group_by(Density, BOX) %>% summarise(behave = mean(behave)),
    aes(x = Density, y = behave), col = "grey60"
  ) +
  geom_point(
    data = data %>% filter(which_behaviour == "Disp") %>% ## average of observed data at teh density level
      group_by(Density) %>% summarise(behave = mean(behave)),
    aes(x = Density, y = behave), cex = 3
  ) +
  scale_x_continuous("",
    sec.axis =
      sec_axis(
        name = expression(paste("Density (snails.", m^-2, " of release patch)")),
        trans = ~ . / (0.12 * 0.12)
      )
  ) +
  scale_y_continuous("Emigration rate") +
  scale_fill_manual(values = c("grey90", "grey85", "grey75"))

p2b <- newdata %>%
  filter(which_behaviour == "Active") %>%
  ggplot() +
  stat_lineribbon(aes(x = Density, y = .value),
    .width = c(0.66, 0.84, 0.95), point_interval = mean_hdi,
    alpha = 0.9
  ) +
  geom_point(
    data = data %>% filter(which_behaviour == "Active") %>%
      group_by(Density, BOX) %>% summarise(behave = mean(behave)),
    aes(x = Density, y = behave), col = "grey60"
  ) +
  geom_point(
    data = data %>% filter(which_behaviour == "Active") %>%
      group_by(Density) %>% summarise(behave = mean(behave)),
    aes(x = Density, y = behave), cex = 3
  ) +
  scale_x_continuous("Density (snails per box)",
    sec.axis =
      sec_axis(~ . / (0.12 * 0.12))
  ) +
  scale_y_continuous("Probability of activity") +
  scale_fill_manual(values = c("grey90", "grey85", "grey75"))

(p2a / p2b) + plot_annotation(tag_levels = "A") & theme_bw() &
  theme(legend.position = "none")
```

### Figure 3

The next 2 figures are much easier to do if we have a dataset with Dispersal and Activity on two separate columns again. Let's make a clean one from `data0`:

```{r behave-wide}
behave_wide <- data0 %>%
  select(Disp, Active, ID) %>%
  mutate(Disp = as.numeric(Disp == "yes"))
```

We want to show that dispersal and activity are linked. To do that, we need to add the average fixed intercepts for each trait to the average values for the "latent behavioural variable" (random effects of individual ID) for each category (disperser/resident, active/inactive) to get the probability of one as a function of the other:
```{r fig3}

newdata <- as_tibble(ranef(mod, summary = FALSE)$ID[, , "behave_Intercept"]) %>% ## we get the posterior individual level random deviations
  mutate(
    post_act_ifdisp = select(., all_of(subset(behave_wide$ID, behave_wide$Disp == 1))) %>% rowMeans(), # we average out the individuals by categories
    post_act_ifres = select(., all_of(subset(behave_wide$ID, behave_wide$Disp == 0))) %>% rowMeans(),
    post_disp_ifact = select(., all_of(subset(behave_wide$ID, behave_wide$Active == 1))) %>% rowMeans(),
    post_disp_ifstill = select(., all_of(subset(behave_wide$ID, behave_wide$Active == 0))) %>% rowMeans(),
  ) %>%
  cbind(posterior_samples(mod) %>%
    select(meanlogitActive = b_behave_which_behaviourActive, meanlogitDisp = b_behave_which_behaviourDisp)) %>% # we link that to the posterior overall means
  mutate(
    post_act_ifdisp = post_act_ifdisp + meanlogitActive, ## we do the additions
    post_act_ifres = post_act_ifres + meanlogitActive,
    post_disp_ifact = post_disp_ifact + meanlogitDisp,
    post_disp_ifstill = post_disp_ifstill + meanlogitDisp
  ) %>%
  select(post_act_ifdisp, post_act_ifres, post_disp_ifact, post_disp_ifstill) # we keep only these variables

## now the plot

p3a <- newdata %>%
  invlogit() %>% # back transform from logit scale back to proportions
  select(post_act_ifdisp, post_act_ifres) %>% # this is the activity = f(dispersal) subplot; we select the columns accordingly
  pivot_longer(everything(), names_to = "Disp") %>%
  mutate(Disp = fct_recode(Disp, `0` = "post_act_ifres", `1` = "post_act_ifdisp")) %>%
  ggplot() +
  geom_col(
    data = behave_wide %>% # observed data
      group_by(Disp) %>%
      summarise(Active = mean(Active == 1)),
    aes(x = factor(Disp), y = Active),
    col = "black", fill = "white"
  ) +
  stat_eye(aes(x = Disp, y = value),
    .width = 0.95, interval_size = 1, slab_alpha=0.9,
    point_size = 3, point_interval = mean_hdi
  ) +
  scale_x_discrete("Dispersal status",
    labels = c(
      paste("Resident (n=", sum(behave_wide$Disp == 0), ")", sep = ""),
      paste("Disperser (n=", sum(behave_wide$Disp == 1), ")", sep = "")
    )
  ) +
  scale_y_continuous("Activity probability", breaks = seq(0, 1, 0.2), limits = c(0, 1.08))

p3b <- newdata %>%
  invlogit() %>%
  select(post_disp_ifact, post_disp_ifstill) %>%
  pivot_longer(everything(), names_to = "Active") %>%
  mutate(Active = fct_recode(Active, `0` = "post_disp_ifstill", `1` = "post_disp_ifact")) %>%
  ggplot() +
  geom_col(
    data = behave_wide %>%
      group_by(Active) %>%
      summarise(Disp = mean(Disp)),
    aes(x = factor(Active), y = Disp),
    col = "black", fill = "white"
  ) +
  stat_eye(aes(x = Active, y = value),
    .width = 0.95, interval_size = 1, slab_alpha=0.9,
    point_size = 3, point_interval = mean_hdi
  ) +
  scale_x_discrete("Active post dispersal?",
    labels = c(
      paste("no (n=", sum(behave_wide$Active == 0), ")", sep = ""),
      paste("yes (n=", sum(behave_wide$Active == 1), ")", sep = "")
    )
  ) +
  scale_y_continuous("Dispersal rate", breaks = seq(0, 1, 0.2), limits = c(0, 1.08))

p3a + p3b &
  theme_bw() &
  theme(
    legend.position = "none", panel.border = element_blank(),
    panel.grid.minor.y = element_blank(),
    axis.line = element_line(colour = "black")
  )
### it looks like there is a link

### let's confirm it!
(newdata$post_disp_ifact - newdata$post_disp_ifstill) %>% mean_hdi()
(newdata$post_act_ifdisp - newdata$post_act_ifres) %>% mean_hdi()

(invlogit(newdata$post_disp_ifact) - invlogit(newdata$post_disp_ifstill)) %>% mean_hdi()
(invlogit(newdata$post_act_ifdisp) - invlogit(newdata$post_act_ifres)) %>% mean_hdi()

## the multiplicative comparison, for the text of the results
(invlogit(newdata$post_disp_ifact) / invlogit(newdata$post_disp_ifstill)) %>% mean_hdi()
(invlogit(newdata$post_act_ifdisp) / invlogit(newdata$post_act_ifres)) %>% mean_hdi()
```

### Figure 4

For the last figure, we want to show the expected relative shell mass for individual behaving differently (Disperser-Active, Disperser-Inactive, Resident-Active and Resident-Inactive). To do that, we need the random effect of individual ID for shell_mass:
```{r fig4}

## associate the names of the posteriors with their legends, for later
levels <- c("post_disp_act", "post_res_act", "post_disp_still", "post_res_still")
names(levels) <- c(
  paste("Disperser and Active (n=", sum(behave_wide$Disp == 1 & behave_wide$Active == 1), ")", sep = ""),
  paste("Resident and Active (n=", sum(behave_wide$Disp == 0 & behave_wide$Active == 1), ")", sep = ""),
  paste("Disperser and Inactive (n=", sum(behave_wide$Disp == 1 & behave_wide$Active == 0), ")", sep = ""),
  paste("Resident and Inactive (n=", sum(behave_wide$Disp == 0 & behave_wide$Active == 0), ")", sep = "")
)


as_tibble(ranef(mod, summary = FALSE)$ID[, , "scalelogshellmass_Intercept"]) %>%
  # same in figure 3, except for the shell random effect, and we split in 4 categories, rather than 2 for disp, and then 2 for activity in a second plot
  mutate(
    post_disp_act = select(., all_of(subset(behave_wide$ID, behave_wide$Disp == 1 & behave_wide$Active == 1))) %>% rowMeans(na.rm = TRUE),
    post_res_act = select(., all_of(subset(behave_wide$ID, behave_wide$Disp == 0 & behave_wide$Active == 1))) %>% rowMeans(na.rm = TRUE),
    post_disp_still = select(., all_of(subset(behave_wide$ID, behave_wide$Disp == 1 & behave_wide$Active == 0))) %>% rowMeans(na.rm = TRUE),
    post_res_still = select(., all_of(subset(behave_wide$ID, behave_wide$Disp == 0 & behave_wide$Active == 0))) %>% rowMeans(na.rm = TRUE),
  ) %>%
  select(post_disp_act, post_disp_still, post_res_act, post_res_still) %>%
  pivot_longer(everything()) %>%
  mutate(name = fct_recode(name, !!!levels)) %>%
  ggplot() +
  geom_hline(yintercept = 1, lty = 2) +
  stat_eye(aes(x = name, y = exp(value * attr(data$scale_logshellmass, "scaled:scale"))),
    # we rescale the random deviations and then, reexponentiate them to get relative deviations
    # (remember, shell mass was log-transformed then scaled?)
    .width = 0.95, interval_size = 1,
    point_size = 3, point_interval = mean_hdi, alpha = 0.9
  ) +
  scale_x_discrete("") +
  scale_y_continuous("Average relative shell mass (posterior)", breaks = c(0.95, 1, 1.05)) +
  theme_bw() +
  theme(
    legend.position = "none", panel.border = element_blank(),
    axis.line = element_line(colour = "black")
  )
```

## **Supplementary Materials**

We also present some models in Supplementary Materials. 

The first two are used to check there is no strong evidence of biased sex-ratio in our dataset:

```{r supplementary-model1a}

#### models for supplementary
if (file.exists(here("R_output", "model_S1a.Rdata")))
# this if-else statement is avoid re-fitting a model when knitting Rmd file if there is already one existing in R_output
# to override, re-run the model and re-save manually by selecting relevant code lines then knit (or delete the Rdata object)
  {
    load(here("R_output", "model_S1a.Rdata"))
  } else {
  mod_S1a <- data %>%
    filter(measurement_order == 1) %>%
    ## filter to avoid duplicates (remember? each individual in present twice in the "data" dataset)
    group_by(BOX) %>%
    summarise(Density = mean(Density), Nfemales = sum(Sex_dissection == "F")) %>% # we group by box
    ungroup() %>%
    brm(Nfemales | trials(Density) ~ 1,
      family = binomial,
      prior = c(set_prior("normal(0,1.5)", class = "Intercept")), data = ., seed = 42
    )

  save(list = "mod_S1a", file = here("R_output", "model_S1a.Rdata"))
}

mod_S1a %>%
  posterior_samples() %>%
  select(contains("Intercept")) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mutate(value = invlogit(value)) %>%
  mean_hdi()
```

```{r supplementary-model1b}
if (file.exists(here("R_output", "model_S1b.Rdata")))
### same as above, but this time by density (as a category)
  {
    load(here("R_output", "model_S1b.Rdata"))
  } else {
  mod_S1b <- data %>%
    filter(measurement_order == 1) %>%
    group_by(BOX) %>%
    summarise(Density = mean(Density), Nfemales = sum(Sex_dissection == "F")) %>%
    ungroup() %>%
    brm(Nfemales | trials(Density) ~ 0 + factor(Density),
      family = binomial,
      prior = c(set_prior("normal(0,1.5)", class = "b")), data = ., seed = 42
    )

  save(list = "mod_S1b", file = here("R_output", "model_S1b.Rdata"))
}

mod_S1b %>%
  posterior_samples() %>%
  select(starts_with(c("Intercept", "b_"))) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mutate(value = invlogit(value)) %>%
  mean_hdi()
```

... and the third one is used to confirm our result that dispersal and activity are linked, with a more "classical" univariate approach than the one we used in the main model:
```{r supplementary-model3}
if (file.exists(here("R_output", "model_S3.Rdata")))
# this if-else statement is avoid re-fitting a model when knitting Rmd file if there is already one existing in R_output
# to override, re-run the model and re-save manually by selecting relevant code lines then knit (or delete the Rdata object)
  {
    load(here("R_output", "model_S3.Rdata"))
  } else {
  mod_S3 <- data %>%
    filter(which_behaviour == "Active") %>% # we want to use Activity as a response
    brm(behave ~ scale_Density + scale_logheight + is.female + Disp2 + (1 | Date) + (1 | BOX),
      family = bernoulli,
      prior = c(
        set_prior("normal(0,1.5)", class = "Intercept"),
        set_prior("normal(0,1)", class = "b"),
        set_prior("normal(0,1)", class = "sd")
      ), data = ., seed = 42, control = list(adapt_delta = 0.95), iter = 6000, warmup = 3000, chains = 4
    )
  save(list = "mod_S3", file = here("R_output", "model_S3.Rdata"))
}

mod_S3 %>%
  posterior_samples() %>%
  select(starts_with(c("Intercept", "b_", "sd_"))) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi()
```

We can do the converse model, with dispersal as the response and activity as the covariate:
```{r supplementary-model3bis}
if (file.exists(here("R_output", "model_S3bis.Rdata")))
# this if-else statement is avoid re-fitting a model when knitting Rmd file if there is already one existing in R_output
# to override, re-run the model and re-save manually by selecting relevant code lines then knit (or delete the Rdata object)
  {
    load(here("R_output", "model_S3bis.Rdata"))
  } else {
  mod_S3bis <- data %>%
    group_by(uniqueID) %>%
    filter(which_behaviour == "Disp") %>%
    brm(behave ~ scale_Density + scale_logheight + is.female + Active2 + (1 | Date) + (1 | BOX),
      family = bernoulli,
      prior = c(
        set_prior("normal(0,1.5)", class = "Intercept"),
        set_prior("normal(0,1)", class = "b"),
        set_prior("normal(0,1)", class = "sd")
      ), data = ., seed = 42, control = list(adapt_delta = 0.99), iter = 6000, warmup = 3000, chains = 4
    )
  save(list = "mod_S3bis", file = here("R_output", "model_S3bis.Rdata"))
}
mod_S3bis %>%
  posterior_samples() %>%
  select(starts_with(c("Intercept", "b_", "sd_"))) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi()
```

We end this with two supplementary figures. One showing how the average "latent behavioural variable" differs between dispersers ad residents, or between active and inactive individuals:

```{r figS5}

newdata <- as_tibble(ranef(mod, summary = FALSE)$ID[, , "behave_Intercept"]) %>%
  mutate(
    post_act_ifdisp = select(., all_of(subset(behave_wide$ID, behave_wide$Disp == 1))) %>% rowMeans(),
    post_act_ifres = select(., all_of(subset(behave_wide$ID, behave_wide$Disp == 0))) %>% rowMeans(),
    post_disp_ifact = select(., all_of(subset(behave_wide$ID, behave_wide$Active == 1))) %>% rowMeans(),
    post_disp_ifstill = select(., all_of(subset(behave_wide$ID, behave_wide$Active == 0))) %>% rowMeans(),
  ) %>%
  select(post_act_ifdisp, post_act_ifres, post_disp_ifact, post_disp_ifstill)

pS5a <- newdata %>%
  select(post_act_ifdisp, post_act_ifres) %>%
  pivot_longer(everything(), names_to = "Disp") %>%
  mutate(Disp = fct_recode(Disp, `0` = "post_act_ifres", `1` = "post_act_ifdisp")) %>%
  mutate(Disp = fct_relevel(Disp, "1", after = Inf)) %>%
  ggplot() +
  stat_eye(aes(x = Disp, y = value),
    .width = 0.95, interval_size = 1,
    point_size = 3, point_interval = mean_hdi, alpha = 0.9
  ) +
  scale_x_discrete("Dispersal status",
    labels = c(
      paste("Resident (n=", sum(behave_wide$Disp == 0), ")", sep = ""),
      paste("Disperser (n=", sum(behave_wide$Disp == 1), ")", sep = "")
    )
  ) +
  scale_y_continuous("average individual-level BLUP (posterior)", limits = c(-1.5, 1.5))

pS5b <- newdata %>%
  select(post_disp_ifact, post_disp_ifstill) %>%
  pivot_longer(everything(), names_to = "Active") %>%
  mutate(Active = fct_recode(Active, `0` = "post_disp_ifstill", `1` = "post_disp_ifact")) %>%
  mutate(Active = fct_relevel(Active, "1", after = Inf)) %>%
  ggplot() +
  stat_eye(aes(x = Active, y = value, alpha = Active),
    .width = 0.95, interval_size = 1,
    point_size = 3, point_interval = mean_hdi, alpha = 0.9
  ) +
  scale_x_discrete("Active post dispersal?",
    labels = c(
      paste("no (n=", sum(behave_wide$Active == 0), ")", sep = ""),
      paste("yes (n=", sum(behave_wide$Active == 1), ")", sep = "")
    )
  ) +
  scale_y_continuous("", limits = c(-1.5, 1.5))

pS5a + pS5b &
  theme_bw() &
  theme(
    legend.position = "none", panel.border = element_blank(),
    panel.grid.minor.y = element_blank(),
    axis.line = element_line(colour = "black")
  )
### it looks like there is a link
```

and another corresponding essentially, to the pairwise difference plot of the plot shown in Fig. 4:

```{r figS6}

levels <- c("post_disp_act", "post_res_act", "post_disp_still", "post_res_still")
names(levels) <- c(
  "Disperser and Active",
  "Resident and Active",
  "Disperser and Inactive",
  "Resident and Inactive"
)


as_tibble(ranef(mod, summary = FALSE)$ID[, , "scalelogshellmass_Intercept"]) %>%
  mutate(
    post_disp_act = select(., all_of(subset(behave_wide$ID, behave_wide$Disp == 1 & behave_wide$Active == 1))) %>% rowMeans(na.rm = TRUE),
    post_res_act = select(., all_of(subset(behave_wide$ID, behave_wide$Disp == 0 & behave_wide$Active == 1))) %>% rowMeans(na.rm = TRUE),
    post_disp_still = select(., all_of(subset(behave_wide$ID, behave_wide$Disp == 1 & behave_wide$Active == 0))) %>% rowMeans(na.rm = TRUE),
    post_res_still = select(., all_of(subset(behave_wide$ID, behave_wide$Disp == 0 & behave_wide$Active == 0))) %>% rowMeans(na.rm = TRUE),
  ) %>%
  select(post_disp_act, post_disp_still, post_res_act, post_res_still) %>%
  mutate(.iteration = 1:dim(.)[1]) %>%
  pivot_longer(matches("post")) %>%
  mutate(name = fct_recode(name, !!!levels)) %>%
  mutate(value = exp(value * attr(data$scale_logshellmass, "scaled:scale"))) %>% ## we unstandardize and then we "un-log"
  compare_levels(variable = value, by = name) %>%
  ggplot() +
  geom_vline(xintercept = 0, lty = 2) +
  stat_halfeye(aes(value, name),
    .width = 0.95, interval_size = 1, point_size = 3, point_interval = mean_hdi, alpha = 0.9
  ) +
  scale_y_discrete("") +
  scale_x_continuous("Posterior mean difference in relative shell mass") +
  theme_bw() +
  theme(legend.position = "none", panel.border = element_blank(), axis.line = element_line(colour = "black"))
```
